{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "74f153c4",
   "metadata": {},
   "outputs": [],
   "source": [
    "from __future__ import print_function\n",
    "import torch\n",
    "import torch.nn as nn\n",
    "import torch.optim as optim\n",
    "import torch.nn.functional as F\n",
    "import torch.backends.cudnn as cudnn\n",
    "import torchvision\n",
    "import numpy as np\n",
    "import torchvision.transforms as transforms\n",
    "import os\n",
    "import sys\n",
    "#from models import *\n",
    "sys.path.append(\"../..\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "b79b1121",
   "metadata": {},
   "outputs": [],
   "source": [
    "import torch.nn as nn\n",
    "class SEWeightModule(nn.Module):\n",
    "    def __init__(self, channels, reduction=4):\n",
    "        super(SEWeightModule, self).__init__()\n",
    "        self.avg_pool = nn.AdaptiveAvgPool2d(1)\n",
    "        self.fc1 = nn.Conv2d(channels, channels//reduction, kernel_size=1, padding=0)\n",
    "        self.relu = nn.ReLU(inplace=True)\n",
    "        self.fc2 = nn.Conv2d(channels//reduction, channels, kernel_size=1, padding=0)\n",
    "        self.sigmoid = nn.Sigmoid()\n",
    "\n",
    "    def forward(self, x):\n",
    "        out = self.avg_pool(x)\n",
    "        out = self.fc1(out)\n",
    "        out = self.relu(out)\n",
    "        out = self.fc2(out)\n",
    "        weight = self.sigmoid(out)\n",
    "\n",
    "        return weight"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "id": "da00b34a",
   "metadata": {},
   "outputs": [],
   "source": [
    "import torch\n",
    "import torch.nn as nn\n",
    "from torch.nn import functional as F\n",
    "\n",
    "\n",
    "class RB1(nn.Module):\n",
    "    def __init__(self, in_channels, out_channels):\n",
    "        \n",
    "        super(RB1, self).__init__()\n",
    "        aa=2\n",
    "        self.conv1 = nn.Conv2d(in_channels, out_channels//aa, kernel_size=3, stride=1, padding=1,dilation=1)\n",
    "        self.bn1 = nn.BatchNorm2d(out_channels//aa)\n",
    "        \n",
    "        self.conv2 = nn.Conv2d(in_channels, out_channels//aa, kernel_size=3, stride=1, padding=2,dilation=2)\n",
    "        self.bn2 = nn.BatchNorm2d(out_channels//aa)\n",
    "        \n",
    "        self.conv3 = nn.Conv2d(in_channels, out_channels//aa, kernel_size=3, stride=1, padding=3,dilation=3)\n",
    "        self.bn3 = nn.BatchNorm2d(out_channels//aa)\n",
    "        \n",
    "        self.conv4 = nn.Conv2d(in_channels, out_channels//aa, kernel_size=3, stride=1, padding=4,dilation=4)\n",
    "        self.bn4 = nn.BatchNorm2d(out_channels//aa)        \n",
    "        \n",
    "        self.conv6 = nn.Conv2d(out_channels*4//aa, out_channels, kernel_size=3, stride=1, padding=1)\n",
    "        self.bn6 = nn.BatchNorm2d(out_channels)  \n",
    "\n",
    "        self.conv7 = nn.Conv2d(in_channels, out_channels, kernel_size=1, stride=1, padding=0)\n",
    "        self.bn7 = nn.BatchNorm2d(out_channels)          \n",
    "        \n",
    "        #self.Drop =torch.nn.Dropout(p=0.2, inplace=False)\n",
    "        self.p = nn.PReLU()\n",
    "        self.se = SEWeightModule(out_channels*2,2)\n",
    "\n",
    "    def forward(self, x):\n",
    "        output1 = self.conv1(x)\n",
    "        output1 = self.p(self.bn1(output1))\n",
    "        \n",
    "        output2 = self.conv2(x)\n",
    "        output2 = self.p(self.bn2(output2))       \n",
    "        \n",
    "        output3 = self.conv3(x)\n",
    "        output3 = self.p(self.bn3(output3))     \n",
    "        \n",
    "        output4 = self.conv4(x)\n",
    "        output4 = self.p(self.bn4(output4))\n",
    "        \n",
    "        output = torch.cat([output1,output2,output3,output4], 1)\n",
    "        Woutput= self.se(output)\n",
    "        output = output * Woutput\n",
    "        \n",
    "        xd = self.conv7(x)\n",
    "        xd = self.p(self.bn7(xd))  \n",
    "        \n",
    "        #print((output+xd).shape)\n",
    "        \n",
    "        #output6 = self.conv6( output+xd )\n",
    "        output6 = self.conv6(output) \n",
    "        output6 = self.p(self.bn6(output6)+xd )\n",
    "\n",
    "        return output6 \n",
    "                         \n",
    "import torch\n",
    "import torch.nn as nn\n",
    "from torch.nn import functional as F\n",
    "\n",
    "\n",
    "class RB2(nn.Module):\n",
    "    def __init__(self, in_channels, out_channels):\n",
    "\n",
    "        super(RB2, self).__init__()\n",
    "        aa=2\n",
    "        self.conv1 = nn.Conv2d(in_channels, out_channels//aa, kernel_size=3, stride=1, padding=1,dilation=1)\n",
    "        self.bn1 = nn.BatchNorm2d(out_channels//aa)\n",
    "        \n",
    "        self.conv2 = nn.Conv2d(in_channels, out_channels//aa, kernel_size=3, stride=1, padding=2,dilation=2)\n",
    "        self.bn2 = nn.BatchNorm2d(out_channels//aa)\n",
    "        \n",
    "        self.conv3 = nn.Conv2d(in_channels, out_channels//aa, kernel_size=3, stride=1, padding=3,dilation=3)\n",
    "        self.bn3 = nn.BatchNorm2d(out_channels//aa)\n",
    "        \n",
    "        self.conv4 = nn.Conv2d(in_channels, out_channels//aa, kernel_size=3, stride=1, padding=4,dilation=4)\n",
    "        self.bn4 = nn.BatchNorm2d(out_channels//aa)          \n",
    "        \n",
    "        self.conv6 = nn.Conv2d(out_channels*4//aa, out_channels, kernel_size=3, stride=1, padding=1)\n",
    "        self.bn6 = nn.BatchNorm2d(out_channels)  \n",
    "\n",
    "        self.conv7 = nn.Conv2d(in_channels, out_channels, kernel_size=1, stride=1, padding=0)\n",
    "        self.bn7 = nn.BatchNorm2d(out_channels)          \n",
    "        \n",
    "        #self.Drop =torch.nn.Dropout(p=0.2, inplace=False)\n",
    "        self.p = nn.PReLU()\n",
    "        self.se = SEWeightModule(out_channels*2,2)\n",
    "\n",
    "    def forward(self, x):\n",
    "        output1 = self.conv1(x)\n",
    "        output1 = self.p(self.bn1(output1))\n",
    "        \n",
    "        output2 = self.conv2(x)\n",
    "        output2 = self.p(self.bn2(output2))       \n",
    "        \n",
    "        output3 = self.conv3(x)\n",
    "        output3 = self.p(self.bn3(output3))     \n",
    "        \n",
    "        output4 = self.conv4(x)\n",
    "        output4 = self.p(self.bn4(output4))\n",
    "        \n",
    "        output = torch.cat([output1,output2,output3,output4], 1)\n",
    "        Woutput= self.se(output)\n",
    "        output = output * Woutput\n",
    "        \n",
    "        xd = self.conv7( x)\n",
    "        xd = self.p(self.bn7(xd))  \n",
    "        \n",
    "        output6 = self.conv6(output)    \n",
    "        output6 = self.p(self.bn6(output6)+xd )       \n",
    "\n",
    "        return output6 \n",
    "    \n",
    "import torch\n",
    "import torch.nn as nn\n",
    "from torch.nn import functional as F\n",
    "\n",
    "\n",
    "class RB3(nn.Module):\n",
    "    def __init__(self, in_channels, out_channels):\n",
    "        \n",
    "        super(RB3, self).__init__()\n",
    "        aa=2\n",
    "        self.conv1 = nn.Conv2d(in_channels, out_channels//aa, kernel_size=3, stride=1, padding=1,dilation=1)\n",
    "        self.bn1 = nn.BatchNorm2d(out_channels//aa)\n",
    "        \n",
    "        self.conv2 = nn.Conv2d(in_channels, out_channels//aa, kernel_size=3, stride=1, padding=2,dilation=2)\n",
    "        self.bn2 = nn.BatchNorm2d(out_channels//aa)\n",
    "        \n",
    "        self.conv3 = nn.Conv2d(in_channels, out_channels//aa, kernel_size=3, stride=1, padding=3,dilation=3)\n",
    "        self.bn3 = nn.BatchNorm2d(out_channels//aa)\n",
    "        \n",
    "        self.conv4 = nn.Conv2d(in_channels, out_channels//aa, kernel_size=3, stride=1, padding=4,dilation=4)\n",
    "        self.bn4 = nn.BatchNorm2d(out_channels//aa)             \n",
    "        \n",
    "        self.conv6 = nn.Conv2d(out_channels*4//aa, 64, kernel_size=3, stride=1, padding=1, groups=2)\n",
    "        \n",
    "        self.bn6 = nn.BatchNorm2d(64)  \n",
    "        \n",
    "\n",
    "        self.conv7 = nn.Conv2d(in_channels, 64, kernel_size=1, stride=1, padding=0)\n",
    "        self.bn7 = nn.BatchNorm2d(64)          \n",
    "        \n",
    "        #self.Drop =torch.nn.Dropout(p=0.2, inplace=False)\n",
    "        self.p = nn.PReLU()\n",
    "        self.se = SEWeightModule(out_channels*2,2)\n",
    "\n",
    "    def forward(self, x):\n",
    "        output1 = self.conv1(x)\n",
    "        output1 = self.p(self.bn1(output1))\n",
    "        \n",
    "        output2 = self.conv2(x)\n",
    "        output2 = self.p(self.bn2(output2))       \n",
    "        \n",
    "        output3 = self.conv3(x)\n",
    "        output3 = self.p(self.bn3(output3))     \n",
    "        \n",
    "        output4 = self.conv4(x)\n",
    "        output4 = self.p(self.bn4(output4))\n",
    "        \n",
    "        output = torch.cat([output1,output2,output3,output4], 1)\n",
    "        Woutput= self.se(output)\n",
    "        output = output * Woutput\n",
    "        \n",
    "        xd = self.conv7( x)\n",
    "        xd = self.p(self.bn7(xd))  \n",
    "        \n",
    "        output6 = self.conv6(output)    \n",
    "        output6 = self.p(self.bn6(output6)+xd )      \n",
    "\n",
    "        return output6 \n",
    "    \n",
    "import torch\n",
    "import torch.nn as nn\n",
    "from torch.nn import functional as F\n",
    "\n",
    "\n",
    "class MAPB(nn.Module):\n",
    "    def __init__(self):\n",
    "        \n",
    "        super(MAPB, self).__init__()\n",
    "        self.conv1 = RB1(1,16)\n",
    "        self.conv2 = RB2(16,32)\n",
    "        self.conv3 = RB2(32,32)\n",
    "        \n",
    "        self.avgpool = nn.AdaptiveAvgPool2d(output_size=(1, 1))\n",
    "        self.fc1 = nn.Linear(32, 14)\n",
    "\n",
    "    def forward(self, x):\n",
    "        x = self.conv1(x)\n",
    "        x = self.conv2(x)\n",
    "        out = self.conv3(x)\n",
    "        \n",
    "        out = self.avgpool(out)\n",
    "        out1 = out.reshape(x.shape[0], -1)\n",
    "        out = self.fc1(out1)\n",
    "\n",
    "        return out1,out    "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "id": "f620238c",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "----------------------------------------------------------------\n",
      "        Layer (type)               Output Shape         Param #\n",
      "================================================================\n",
      "            Conv2d-1            [-1, 8, 64, 64]              80\n",
      "       BatchNorm2d-2            [-1, 8, 64, 64]              16\n",
      "             PReLU-3            [-1, 8, 64, 64]               1\n",
      "            Conv2d-4            [-1, 8, 64, 64]              80\n",
      "       BatchNorm2d-5            [-1, 8, 64, 64]              16\n",
      "             PReLU-6            [-1, 8, 64, 64]               1\n",
      "            Conv2d-7            [-1, 8, 64, 64]              80\n",
      "       BatchNorm2d-8            [-1, 8, 64, 64]              16\n",
      "             PReLU-9            [-1, 8, 64, 64]               1\n",
      "           Conv2d-10            [-1, 8, 64, 64]              80\n",
      "      BatchNorm2d-11            [-1, 8, 64, 64]              16\n",
      "            PReLU-12            [-1, 8, 64, 64]               1\n",
      "AdaptiveAvgPool2d-13             [-1, 32, 1, 1]               0\n",
      "           Conv2d-14             [-1, 16, 1, 1]             528\n",
      "             ReLU-15             [-1, 16, 1, 1]               0\n",
      "           Conv2d-16             [-1, 32, 1, 1]             544\n",
      "          Sigmoid-17             [-1, 32, 1, 1]               0\n",
      "   SEWeightModule-18             [-1, 32, 1, 1]               0\n",
      "           Conv2d-19           [-1, 16, 64, 64]              32\n",
      "      BatchNorm2d-20           [-1, 16, 64, 64]              32\n",
      "            PReLU-21           [-1, 16, 64, 64]               1\n",
      "           Conv2d-22           [-1, 16, 64, 64]           4,624\n",
      "      BatchNorm2d-23           [-1, 16, 64, 64]              32\n",
      "            PReLU-24           [-1, 16, 64, 64]               1\n",
      "              RB1-25           [-1, 16, 64, 64]               0\n",
      "           Conv2d-26           [-1, 16, 64, 64]           2,320\n",
      "      BatchNorm2d-27           [-1, 16, 64, 64]              32\n",
      "            PReLU-28           [-1, 16, 64, 64]               1\n",
      "           Conv2d-29           [-1, 16, 64, 64]           2,320\n",
      "      BatchNorm2d-30           [-1, 16, 64, 64]              32\n",
      "            PReLU-31           [-1, 16, 64, 64]               1\n",
      "           Conv2d-32           [-1, 16, 64, 64]           2,320\n",
      "      BatchNorm2d-33           [-1, 16, 64, 64]              32\n",
      "            PReLU-34           [-1, 16, 64, 64]               1\n",
      "           Conv2d-35           [-1, 16, 64, 64]           2,320\n",
      "      BatchNorm2d-36           [-1, 16, 64, 64]              32\n",
      "            PReLU-37           [-1, 16, 64, 64]               1\n",
      "AdaptiveAvgPool2d-38             [-1, 64, 1, 1]               0\n",
      "           Conv2d-39             [-1, 32, 1, 1]           2,080\n",
      "             ReLU-40             [-1, 32, 1, 1]               0\n",
      "           Conv2d-41             [-1, 64, 1, 1]           2,112\n",
      "          Sigmoid-42             [-1, 64, 1, 1]               0\n",
      "   SEWeightModule-43             [-1, 64, 1, 1]               0\n",
      "           Conv2d-44           [-1, 32, 64, 64]             544\n",
      "      BatchNorm2d-45           [-1, 32, 64, 64]              64\n",
      "            PReLU-46           [-1, 32, 64, 64]               1\n",
      "           Conv2d-47           [-1, 32, 64, 64]          18,464\n",
      "      BatchNorm2d-48           [-1, 32, 64, 64]              64\n",
      "            PReLU-49           [-1, 32, 64, 64]               1\n",
      "              RB2-50           [-1, 32, 64, 64]               0\n",
      "           Conv2d-51           [-1, 16, 64, 64]           4,624\n",
      "      BatchNorm2d-52           [-1, 16, 64, 64]              32\n",
      "            PReLU-53           [-1, 16, 64, 64]               1\n",
      "           Conv2d-54           [-1, 16, 64, 64]           4,624\n",
      "      BatchNorm2d-55           [-1, 16, 64, 64]              32\n",
      "            PReLU-56           [-1, 16, 64, 64]               1\n",
      "           Conv2d-57           [-1, 16, 64, 64]           4,624\n",
      "      BatchNorm2d-58           [-1, 16, 64, 64]              32\n",
      "            PReLU-59           [-1, 16, 64, 64]               1\n",
      "           Conv2d-60           [-1, 16, 64, 64]           4,624\n",
      "      BatchNorm2d-61           [-1, 16, 64, 64]              32\n",
      "            PReLU-62           [-1, 16, 64, 64]               1\n",
      "AdaptiveAvgPool2d-63             [-1, 64, 1, 1]               0\n",
      "           Conv2d-64             [-1, 32, 1, 1]           2,080\n",
      "             ReLU-65             [-1, 32, 1, 1]               0\n",
      "           Conv2d-66             [-1, 64, 1, 1]           2,112\n",
      "          Sigmoid-67             [-1, 64, 1, 1]               0\n",
      "   SEWeightModule-68             [-1, 64, 1, 1]               0\n",
      "           Conv2d-69           [-1, 32, 64, 64]           1,056\n",
      "      BatchNorm2d-70           [-1, 32, 64, 64]              64\n",
      "            PReLU-71           [-1, 32, 64, 64]               1\n",
      "           Conv2d-72           [-1, 32, 64, 64]          18,464\n",
      "      BatchNorm2d-73           [-1, 32, 64, 64]              64\n",
      "            PReLU-74           [-1, 32, 64, 64]               1\n",
      "              RB2-75           [-1, 32, 64, 64]               0\n",
      "AdaptiveAvgPool2d-76             [-1, 32, 1, 1]               0\n",
      "           Linear-77                   [-1, 14]             462\n",
      "================================================================\n",
      "Total params: 81,856\n",
      "Trainable params: 81,856\n",
      "Non-trainable params: 0\n",
      "----------------------------------------------------------------\n",
      "Input size (MB): 0.02\n",
      "Forward/backward pass size (MB): 32.51\n",
      "Params size (MB): 0.31\n",
      "Estimated Total Size (MB): 32.83\n",
      "----------------------------------------------------------------\n"
     ]
    }
   ],
   "source": [
    "from torchsummary import summary\n",
    "model = MAPB()\n",
    "model = model.to('cuda')\n",
    "summary(model,input_size=(1,64,64))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "id": "ba5f7ce1",
   "metadata": {},
   "outputs": [],
   "source": [
    "net=model"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "id": "548679fb",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "<All keys matched successfully>"
      ]
     },
     "execution_count": 6,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "net.load_state_dict(torch.load(r\"C:\\Users\\cccc\\Desktop\\MAPNET2\\weight.pth\"))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "id": "6c9bfd99",
   "metadata": {},
   "outputs": [],
   "source": [
    "import joblib\n",
    "categories = list(range(0, 14))\n",
    "weibull_model = joblib.load('weibull_model.pkl')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "id": "d49c15d9",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(4800, 1, 64, 64)"
      ]
     },
     "execution_count": 8,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "X_test1 =np.load(r\"C:\\Users\\cccc\\Desktop\\MAPNET2\\TFI\\X_TEST1.npy\")\n",
    "X_test1.shape\n",
    "X_test1=X_test1.reshape(len(X_test1),1,64,64)\n",
    "X_test1.shape\n",
    "\n",
    "X_test2 =np.load(r\"C:\\Users\\cccc\\Desktop\\MAPNET2\\TFI\\X_TEST2.npy\")\n",
    "X_test2.shape\n",
    "X_test2=X_test2.reshape(len(X_test2),1,64,64)\n",
    "X_test2.shape\n",
    "\n",
    "X_test3 =np.load(r\"C:\\Users\\cccc\\Desktop\\MAPNET2\\TFI\\X_TEST3.npy\")\n",
    "X_test3.shape\n",
    "X_test3=X_test3.reshape(len(X_test3),1,64,64)\n",
    "X_test3.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "id": "97c5aa3d",
   "metadata": {},
   "outputs": [],
   "source": [
    "X_test1=np.concatenate((X_test1,X_test2,X_test3),axis=0)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "id": "0d21d6be",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(14400, 1, 64, 64)"
      ]
     },
     "execution_count": 10,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "X_test1.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "id": "5dbe75bc",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "(14400,)\n",
      "(14400,)\n"
     ]
    }
   ],
   "source": [
    "\n",
    "\n",
    "#X_test1=X_test.reshape(14400,1,224,224)\n",
    "import numpy as np\n",
    "import os\n",
    "#label the results\n",
    "y1 = np.zeros(800)\n",
    "y2 = np.ones(800)*1\n",
    "y3 = np.ones(800)*2\n",
    "y4 = np.ones(800)*3\n",
    "y5 = np.ones(800)*4\n",
    "y6 = np.ones(800)*5\n",
    "y7 = np.ones(800)*6\n",
    "y8 = np.ones(800)*7\n",
    "y9 =  np.ones(800)*8\n",
    "y10 = np.ones(800)*9 \n",
    "y11 = np.ones(800)*10 \n",
    "y12 = np.ones(800)*11 \n",
    "y13 = np.ones(800)*12 \n",
    "y14 = np.ones(800)*13 \n",
    "y15 = np.ones(800*4)*14\n",
    "yy= np.concatenate((y1,y2,y3,y4,y5,y6,y7,y8,y9,y10,y11,y12,y13,y14,y15),axis=0)\n",
    "#yy= yy.reshape(-1,1)\n",
    "print(yy.shape)\n",
    "\n",
    "y = yy\n",
    "#y = y.reshape(-1,1)\n",
    "print(y.shape)\n",
    "ytest1=y"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "id": "b0e2b340",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "array([1.        , 1.        , 1.        , 0.99928571, 1.        ,\n",
       "       0.99785714, 0.99214286, 0.97142857])"
      ]
     },
     "execution_count": 12,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "## CLOSED RECOGNITION\n",
    "net.eval()\n",
    "total = 0\n",
    "acc=np.zeros([14,8])\n",
    "for num_s in range (14):\n",
    "    for num_SNR in range (8):\n",
    "        correct = 0\n",
    "        correct2 = 0\n",
    "        correct3 = 0\n",
    "        scores, labels = [], []\n",
    "\n",
    "        inputs=torch.from_numpy(X_test1[num_s*800+num_SNR*100+0:num_s*800+num_SNR*100+100]).float().cuda()\n",
    "        targets=torch.from_numpy(ytest1[num_s*800+num_SNR*100+0:num_s*800+num_SNR*100+100]).float().cuda()\n",
    "        targets=targets.long()\n",
    "        _,outputs = net(inputs)\n",
    "        scores.append(outputs)\n",
    "        labels.append(targets)\n",
    "        \n",
    "        scores = torch.cat(scores,dim=0).cpu().detach().numpy()\n",
    "        labels = torch.cat(labels,dim=0).cpu().detach().numpy()     \n",
    "        \n",
    "        \n",
    "        \n",
    "        scores = np.array(scores)[:, np.newaxis, :]\n",
    "        labels = np.array(labels) \n",
    "\n",
    "\n",
    "        pre=[]\n",
    "        \n",
    "        for score in scores:\n",
    "            ss = np.argmax(score)\n",
    "            pre.append(ss)\n",
    "            \n",
    "        pre = torch.from_numpy(np.array(pre))\n",
    "\n",
    "        pred= torch.from_numpy(np.array(pre))\n",
    "        labels=torch.from_numpy(np.array(labels))\n",
    "        correct += pred.eq(labels).sum().item()\n",
    "\n",
    "\n",
    "        acc[num_s,num_SNR]=correct/100\n",
    "np.sum(acc,0)/14     "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "id": "ce3326be",
   "metadata": {},
   "outputs": [],
   "source": [
    "## OPEN RECOGNITION"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "id": "a78e179b",
   "metadata": {},
   "outputs": [],
   "source": [
    "import numpy as np\n",
    "import scipy.spatial.distance as spd\n",
    "import torch\n",
    "import libmr\n",
    "\n",
    "\n",
    "def calc_distance(query_score, mcv, eu_weight, distance_type='euclidean'):\n",
    "    if distance_type == 'euclidean':\n",
    "        query_distance = spd.euclidean(mcv, query_score)\n",
    "    elif distance_type == 'cosine':\n",
    "        query_distance = spd.cosine(mcv, query_score)\n",
    "    else:\n",
    "        print(\"distance type not known: enter either of euclidean or cosine\")\n",
    "    return query_distance\n",
    "\n",
    "\n",
    "def fit_weibull(means, dists, categories, tailsize=20, distance_type='euclidean'):\n",
    "    weibull_model = {}\n",
    "    for mean, dist, category_name in zip(means, dists, categories):\n",
    "        weibull_model[category_name] = {}\n",
    "        weibull_model[category_name]['distances_{}'.format(distance_type)] = dist[distance_type]\n",
    "        weibull_model[category_name]['mean_vec'] = mean\n",
    "        weibull_model[category_name]['weibull_model'] = []\n",
    "        for channel in range(mean.shape[0]):\n",
    "            mr = libmr.MR()\n",
    "            tailtofit = np.sort(dist[distance_type][channel, :])[-tailsize:]\n",
    "            mr.fit_high(tailtofit, len(tailtofit))\n",
    "            weibull_model[category_name]['weibull_model'].append(mr)\n",
    "    return weibull_model\n",
    "\n",
    "\n",
    "def query_weibull(category_name, weibull_model, distance_type='euclidean'):\n",
    "    return [weibull_model[category_name]['mean_vec'],\n",
    "            weibull_model[category_name]['distances_{}'.format(distance_type)],\n",
    "            weibull_model[category_name]['weibull_model']]\n",
    "\n",
    "def compute_pro_un_prob(scores, scores_u):\n",
    "    prob_scores, prob_unknowns = [], []\n",
    "    for s, su in zip(scores, scores_u):\n",
    "        channel_scores = np.exp(s)\n",
    "        channel_unknown = np.exp(np.sum(su))\n",
    "\n",
    "        total_denom = np.sum(channel_scores) + channel_unknown\n",
    "        prob_scores.append(channel_scores / total_denom)\n",
    "        prob_unknowns.append(channel_unknown / total_denom)\n",
    "\n",
    "    # Take channel mean\n",
    "    scores = np.mean(prob_scores, axis=0)\n",
    "    unknowns = np.mean(prob_unknowns, axis=0)\n",
    "    modified_scores = scores.tolist() + [unknowns]\n",
    "    return modified_scores\n",
    "\n",
    "\n",
    "def softmax(x):\n",
    "    e_x = np.exp(x - np.max(x))\n",
    "    return e_x / e_x.sum()\n",
    "\n",
    "\n",
    "def pro_un(weibull_model, categories, input_score, eu_weight, alpha=10, distance_type='euclidean'):\n",
    "    nb_classes = len(categories)\n",
    "\n",
    "    ranked_list = input_score.argsort().ravel()[::-1][:alpha]\n",
    "    alpha_weights = [((alpha + 1) - i) / float(alpha) for i in range(1, alpha + 1)]\n",
    "    omega = np.zeros(nb_classes)\n",
    "    omega[ranked_list] = alpha_weights\n",
    "\n",
    "    scores, scores_u = [], []\n",
    "    for channel, input_score_channel in enumerate(input_score):\n",
    "        score_channel, score_channel_u = [], []\n",
    "        for c, category_name in enumerate(categories):\n",
    "            mav, dist, model = query_weibull(category_name, weibull_model, distance_type)\n",
    "            channel_dist = calc_distance(input_score_channel, mav[channel], eu_weight, distance_type)\n",
    "            wscore = model[channel].w_score(channel_dist)\n",
    "            modified_score = input_score_channel[c] * (1 - wscore * omega[c])\n",
    "            score_channel.append(modified_score)\n",
    "            score_channel_u.append(input_score_channel[c] - modified_score)\n",
    "\n",
    "        scores.append(score_channel)\n",
    "        scores_u.append(score_channel_u)\n",
    "\n",
    "    scores = np.asarray(scores)\n",
    "    scores_u = np.asarray(scores_u)\n",
    "\n",
    "    pro_un_prob = np.array(compute_pro_un_prob(scores, scores_u))\n",
    "    softmax_prob = softmax(np.array(input_score.ravel()))\n",
    "    return pro_un_prob, softmax_prob\n",
    "\n",
    "\n",
    "def compute_channel_distances(mavs, features, eu_weight=0.5):\n",
    "\n",
    "    eucos_dists, eu_dists, cos_dists = [], [], []\n",
    "    for channel, mcv in enumerate(mavs):  \n",
    "        eu_dists.append([spd.euclidean(mcv, feat[channel]) for feat in features])\n",
    "        cos_dists.append([spd.cosine(mcv, feat[channel]) for feat in features])\n",
    "        eucos_dists.append([spd.euclidean(mcv, feat[channel]) * eu_weight +\n",
    "                            spd.cosine(mcv, feat[channel]) for feat in features])\n",
    "\n",
    "    return {'eucos': np.array(eucos_dists), 'cosine': np.array(cos_dists), 'euclidean': np.array(eu_dists)}\n",
    "\n",
    "\n",
    "def compute_train_score_and_mavs_and_dists(train_class_num,trainloader,device,net):\n",
    "    scores = [[] for _ in range(train_class_num)]\n",
    "    with torch.no_grad():\n",
    "\n",
    "        for batch_idx, batch in enumerate(trainloader):\n",
    "            inputs,targets = batch[0], batch[1]\n",
    "            inputs  = inputs.cuda()\n",
    "            targets  = targets.cuda()\n",
    "            targets=targets.long()   \n",
    "            \n",
    "\n",
    "            embed_fea1,outputs = net(inputs)\n",
    "            for score, t in zip(outputs, targets):\n",
    "                if torch.argmax(score) == t:\n",
    "                    scores[t].append(score.unsqueeze(dim=0).unsqueeze(dim=0))\n",
    "    scores = [torch.cat(x).cpu().numpy() for x in scores]  # (N_c, 1, C) * C\n",
    "    mavs = np.array([np.mean(x, axis=0) for x in scores])  # (C, 1, C)\n",
    "    dists = [compute_channel_distances(mcv, score) for mcv, score in zip(mavs, scores)]\n",
    "    return scores, mavs, dists\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "id": "dfaf12b2",
   "metadata": {},
   "outputs": [],
   "source": [
    "def Recalibrate(weibull_model, categories, input_score, eu_weight, alpha=10, distance_type='euclidean'):\n",
    "\n",
    "    nb_classes = len(categories)\n",
    "\n",
    "    ranked_list = input_score.argsort().ravel()[::-1][:alpha]\n",
    "    alpha_weights = [((alpha + 1) - i) / float(alpha) for i in range(1, alpha + 1)]\n",
    "    omega = np.zeros(nb_classes)\n",
    "    omega[ranked_list] = alpha_weights\n",
    "\n",
    "    scores, scores_u = [], []\n",
    "    for channel, input_score_channel in enumerate(input_score):\n",
    "        score_channel, score_channel_u = [], []\n",
    "        for c, category_name in enumerate(categories):\n",
    "            mav, dist, model = query_weibull(category_name, weibull_model, distance_type)\n",
    "            channel_dist = calc_distance(input_score_channel, mav[channel], eu_weight, distance_type)\n",
    "            wscore = model[channel].w_score(channel_dist)\n",
    "            modified_score = input_score_channel[c] * (1 - wscore * omega[c])\n",
    "            score_channel.append(modified_score)\n",
    "            score_channel_u.append(input_score_channel[c] - modified_score)\n",
    "\n",
    "        scores.append(score_channel)\n",
    "        scores_u.append(score_channel_u)\n",
    "\n",
    "    scores = np.asarray(scores)\n",
    "    scores_u = np.asarray(scores_u)\n",
    "\n",
    "    Recalibrate_prob = np.array(compute_Recalibrate_prob(scores, scores_u))\n",
    "    softmax_prob = softmax(np.array(input_score.ravel()))\n",
    "    return Recalibrate_prob, softmax_prob\n",
    "\n",
    "def compute_Recalibrate_prob(scores, scores_u):\n",
    "    prob_scores, prob_unknowns = [], []\n",
    "    for s, su in zip(scores, scores_u):\n",
    "        channel_scores = np.exp(s)\n",
    "        channel_unknown = np.exp(np.sum(su))\n",
    "\n",
    "        total_denom = np.sum(channel_scores) + channel_unknown\n",
    "        prob_scores.append(channel_scores / total_denom)\n",
    "        prob_unknowns.append(channel_unknown / total_denom)\n",
    "\n",
    "    # Take channel mean\n",
    "    scores = np.mean(prob_scores, axis=0)\n",
    "    unknowns = np.mean(prob_unknowns, axis=0)\n",
    "    modified_scores = scores.tolist() + [unknowns]\n",
    "    return modified_scores"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "id": "07bffce5",
   "metadata": {},
   "outputs": [],
   "source": [
    "net.eval()\n",
    "\n",
    "total = 0\n",
    "acc=np.zeros([18,8])\n",
    "acc2=np.zeros([18,8])\n",
    "acc3=np.zeros([18,8])\n",
    "for num_s in range (18):\n",
    "    for num_SNR in range (8):\n",
    "        correct = 0\n",
    "        correct2 = 0\n",
    "        correct3 = 0\n",
    "        scores, labels = [], []\n",
    "\n",
    "        inputs=torch.from_numpy(X_test1[num_s*800+num_SNR*100+0:num_s*800+num_SNR*100+100]).float().cuda()\n",
    "        targets=torch.from_numpy(ytest1[num_s*800+num_SNR*100+0:num_s*800+num_SNR*100+100]).float().cuda()\n",
    "        targets=targets.long()\n",
    "        _,outputs = net(inputs)\n",
    "        scores.append(outputs)\n",
    "        labels.append(targets)\n",
    "        \n",
    "        scores = torch.cat(scores,dim=0).cpu().detach().numpy()\n",
    "        labels = torch.cat(labels,dim=0).cpu().detach().numpy()     \n",
    "        \n",
    "        \n",
    "        \n",
    "        scores = np.array(scores)[:, np.newaxis, :]\n",
    "        labels = np.array(labels) \n",
    "\n",
    "        pred_Recalibrate = [] \n",
    "        score_Recalibrate = []\n",
    "        \n",
    "        for score in scores:\n",
    "            so, ss = Recalibrate(weibull_model, categories, score,\n",
    "                             0.5, 3, \"euclidean\")\n",
    "            pred_Recalibrate.append(np.argmax(so))\n",
    "            score_Recalibrate.append(so)        \n",
    "        pred_Recalibrate = torch.from_numpy(np.array(pred_Recalibrate))\n",
    "        \n",
    "        labels=torch.from_numpy(np.array(labels))\n",
    "        correct += pred_Recalibrate.eq(labels).sum().item()\n",
    "\n",
    "        acc[num_s,num_SNR]=correct/100"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "id": "d6d250a9",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "array([[1.  , 1.  , 1.  , 1.  , 1.  , 1.  , 1.  , 0.97],\n",
       "       [1.  , 1.  , 1.  , 1.  , 1.  , 1.  , 0.99, 0.85],\n",
       "       [1.  , 1.  , 1.  , 1.  , 1.  , 1.  , 1.  , 0.98],\n",
       "       [1.  , 1.  , 1.  , 1.  , 1.  , 1.  , 0.99, 0.92],\n",
       "       [1.  , 1.  , 1.  , 1.  , 1.  , 1.  , 1.  , 0.97],\n",
       "       [1.  , 1.  , 1.  , 1.  , 1.  , 1.  , 0.98, 0.89],\n",
       "       [1.  , 1.  , 1.  , 1.  , 0.98, 0.96, 0.93, 0.82],\n",
       "       [1.  , 1.  , 1.  , 1.  , 1.  , 1.  , 1.  , 0.92],\n",
       "       [1.  , 1.  , 1.  , 1.  , 1.  , 0.97, 0.9 , 0.66],\n",
       "       [1.  , 1.  , 1.  , 1.  , 1.  , 0.99, 0.92, 0.81],\n",
       "       [1.  , 1.  , 1.  , 1.  , 1.  , 1.  , 1.  , 0.95],\n",
       "       [1.  , 1.  , 1.  , 0.99, 0.99, 0.95, 0.9 , 0.82],\n",
       "       [1.  , 1.  , 1.  , 1.  , 1.  , 1.  , 0.99, 0.86],\n",
       "       [1.  , 1.  , 1.  , 1.  , 1.  , 1.  , 0.99, 0.98],\n",
       "       [1.  , 1.  , 1.  , 1.  , 1.  , 1.  , 1.  , 0.96],\n",
       "       [1.  , 1.  , 1.  , 0.99, 1.  , 0.99, 1.  , 1.  ],\n",
       "       [1.  , 1.  , 1.  , 1.  , 0.99, 0.98, 0.97, 0.93],\n",
       "       [1.  , 1.  , 1.  , 1.  , 0.99, 0.99, 0.99, 1.  ]])"
      ]
     },
     "execution_count": 17,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "acc"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "id": "c9dfbf77",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "array([1.        , 1.        , 1.        , 0.99928571, 0.99785714,\n",
       "       0.99071429, 0.97071429, 0.88571429])"
      ]
     },
     "execution_count": 18,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "np.mean(acc[0:14],0)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "id": "99f251c1",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "array([1.    , 1.    , 1.    , 0.9975, 0.995 , 0.99  , 0.99  , 0.9725])"
      ]
     },
     "execution_count": 19,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "np.mean(acc[14:18],0)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "id": "127218b8",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "0.9805357142857143"
      ]
     },
     "execution_count": 20,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "np.mean(np.mean(acc[0:14],0))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 21,
   "id": "bc729bf8",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "0.993125"
      ]
     },
     "execution_count": 21,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "np.mean(np.mean(acc[14:18],0))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 22,
   "id": "0b5b564e",
   "metadata": {},
   "outputs": [],
   "source": [
    "#Measured"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 23,
   "id": "b69d4766",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "90\n",
      "50\n",
      "40\n"
     ]
    }
   ],
   "source": [
    "X_test1 =np.load(r\"C:\\Users\\cccc\\Desktop\\MAPNET2\\TFI\\SFM.npy\")\n",
    "X_test1.shape\n",
    "LE=len(X_test1)\n",
    "\n",
    "net.eval()\n",
    "X_test1=X_test1.reshape([LE,1, 64,64])\n",
    "total = 0\n",
    "acc=np.zeros([16,8])\n",
    "acc2=np.zeros([16,8])\n",
    "acc3=np.zeros([16,8])\n",
    "for num_s in range (1):\n",
    "    for num_SNR in range (1):\n",
    "        correct = 0\n",
    "        correct2 = 0\n",
    "        correct3 = 0\n",
    "        scores, labels = [], []\n",
    "\n",
    "        inputs=torch.from_numpy(X_test1).float().cuda()\n",
    "        #targets=torch.from_numpy(ytest1[num_s*800+num_SNR*100+0:num_s*800+num_SNR*100+100]).float().cuda()\n",
    "        #targets=targets.long()\n",
    "        _,outputs = net(inputs)\n",
    "        scores.append(outputs)\n",
    "        labels.append(targets)\n",
    "        \n",
    "        scores = torch.cat(scores,dim=0).cpu().detach().numpy()\n",
    "        labels = torch.cat(labels,dim=0).cpu().detach().numpy()     \n",
    "        \n",
    "        \n",
    "        \n",
    "        scores = np.array(scores)[:, np.newaxis, :]\n",
    "        labels = np.array(labels) \n",
    "\n",
    "        pred_Recalibrate = []\n",
    "        score_Recalibrate = []\n",
    "        \n",
    "        for score in scores:\n",
    "            so, ss = Recalibrate(weibull_model, categories, score,\n",
    "                             0.5, 3, \"euclidean\")\n",
    "            pred_Recalibrate.append(np.argmax(so))\n",
    "            score_Recalibrate.append(so)        \n",
    "        pred_Recalibrate = torch.from_numpy(np.array(pred_Recalibrate))\n",
    "        \n",
    "\n",
    "acc=0\n",
    "for ii in range(100):\n",
    "    if pred_Recalibrate[ii]==1:\n",
    "        acc=acc+1\n",
    "print(acc)   \n",
    "acc=0\n",
    "for ii in range(50):\n",
    "    if pred_Recalibrate[ii]==1:\n",
    "        acc=acc+1\n",
    "print(acc)  \n",
    "acc=0\n",
    "for ii in range(50,100):\n",
    "    if pred_Recalibrate[ii]==1:\n",
    "        acc=acc+1\n",
    "print(acc)  "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 24,
   "id": "e0367d1a",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "98\n",
      "50\n",
      "48\n"
     ]
    }
   ],
   "source": [
    "X_test1 =np.load(r\"C:\\Users\\cccc\\Desktop\\MAPNET2\\TFI\\NS.npy\")\n",
    "X_test1.shape\n",
    "LE=len(X_test1)\n",
    "\n",
    "net.eval()\n",
    "X_test1=X_test1.reshape([LE,1, 64,64])\n",
    "total = 0\n",
    "acc=np.zeros([16,8])\n",
    "acc2=np.zeros([16,8])\n",
    "acc3=np.zeros([16,8])\n",
    "for num_s in range (1):\n",
    "    for num_SNR in range (1):\n",
    "        correct = 0\n",
    "        correct2 = 0\n",
    "        correct3 = 0\n",
    "        scores, labels = [], []\n",
    "\n",
    "        inputs=torch.from_numpy(X_test1).float().cuda()\n",
    "        #targets=torch.from_numpy(ytest1[num_s*800+num_SNR*100+0:num_s*800+num_SNR*100+100]).float().cuda()\n",
    "        #targets=targets.long()\n",
    "        _,outputs = net(inputs)\n",
    "        scores.append(outputs)\n",
    "        labels.append(targets)\n",
    "        \n",
    "        scores = torch.cat(scores,dim=0).cpu().detach().numpy()\n",
    "        labels = torch.cat(labels,dim=0).cpu().detach().numpy()     \n",
    "        \n",
    "        \n",
    "        \n",
    "        scores = np.array(scores)[:, np.newaxis, :]\n",
    "        labels = np.array(labels) \n",
    "\n",
    "        pred_Recalibrate = []\n",
    "        score_Recalibrate = []\n",
    "        \n",
    "        for score in scores:\n",
    "            so, ss = Recalibrate(weibull_model, categories, score,\n",
    "                             0.5, 3, \"euclidean\")\n",
    "            pred_Recalibrate.append(np.argmax(so))\n",
    "            score_Recalibrate.append(so)        \n",
    "        pred_Recalibrate = torch.from_numpy(np.array(pred_Recalibrate))\n",
    "        \n",
    "\n",
    "acc=0\n",
    "for ii in range(100):\n",
    "    if pred_Recalibrate[ii]==4:\n",
    "        acc=acc+1\n",
    "print(acc)   \n",
    "acc=0\n",
    "for ii in range(50):\n",
    "    if pred_Recalibrate[ii]==4:\n",
    "        acc=acc+1\n",
    "print(acc)  \n",
    "acc=0\n",
    "for ii in range(50,100):\n",
    "    if pred_Recalibrate[ii]==4:\n",
    "        acc=acc+1\n",
    "print(acc)  "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 25,
   "id": "331c6ef5",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "84\n",
      "50\n",
      "34\n"
     ]
    }
   ],
   "source": [
    "X_test1 =np.load(r\"C:\\Users\\cccc\\Desktop\\MAPNET2\\TFI\\LFM.npy\")\n",
    "X_test1.shape\n",
    "LE=len(X_test1)\n",
    "\n",
    "net.eval()\n",
    "X_test1=X_test1.reshape([LE,1, 64,64])\n",
    "total = 0\n",
    "acc=np.zeros([16,8])\n",
    "acc2=np.zeros([16,8])\n",
    "acc3=np.zeros([16,8])\n",
    "for num_s in range (1):\n",
    "    for num_SNR in range (1):\n",
    "        correct = 0\n",
    "        correct2 = 0\n",
    "        correct3 = 0\n",
    "        scores, labels = [], []\n",
    "\n",
    "        inputs=torch.from_numpy(X_test1).float().cuda()\n",
    "        #targets=torch.from_numpy(ytest1[num_s*800+num_SNR*100+0:num_s*800+num_SNR*100+100]).float().cuda()\n",
    "        #targets=targets.long()\n",
    "        _,outputs = net(inputs)\n",
    "        scores.append(outputs)\n",
    "        labels.append(targets)\n",
    "        \n",
    "        scores = torch.cat(scores,dim=0).cpu().detach().numpy()\n",
    "        labels = torch.cat(labels,dim=0).cpu().detach().numpy()     \n",
    "        \n",
    "        \n",
    "        \n",
    "        scores = np.array(scores)[:, np.newaxis, :]\n",
    "        labels = np.array(labels) \n",
    "\n",
    "        pred_Recalibrate = []\n",
    "        score_Recalibrate = []\n",
    "        \n",
    "        for score in scores:\n",
    "            so, ss = Recalibrate(weibull_model, categories, score,\n",
    "                             0.5, 3, \"euclidean\")\n",
    "            pred_Recalibrate.append(np.argmax(so))\n",
    "            score_Recalibrate.append(so)        \n",
    "        pred_Recalibrate = torch.from_numpy(np.array(pred_Recalibrate))\n",
    "        \n",
    "\n",
    "acc=0\n",
    "for ii in range(100):\n",
    "    if pred_Recalibrate[ii]==0:\n",
    "        acc=acc+1\n",
    "print(acc)   \n",
    "acc=0\n",
    "for ii in range(50):\n",
    "    if pred_Recalibrate[ii]==0:\n",
    "        acc=acc+1\n",
    "print(acc)  \n",
    "acc=0\n",
    "for ii in range(50,100):\n",
    "    if pred_Recalibrate[ii]==0:\n",
    "        acc=acc+1\n",
    "print(acc)  "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 26,
   "id": "bf96a812",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "100\n"
     ]
    }
   ],
   "source": [
    "X_test1 =np.load(r\"C:\\Users\\cccc\\Desktop\\MAPNET2\\TFI\\UN.npy\")\n",
    "X_test1.shape\n",
    "LE=len(X_test1)\n",
    "\n",
    "net.eval()\n",
    "X_test1=X_test1.reshape([LE,1, 64,64])\n",
    "total = 0\n",
    "acc=np.zeros([16,8])\n",
    "acc2=np.zeros([16,8])\n",
    "acc3=np.zeros([16,8])\n",
    "for num_s in range (1):\n",
    "    for num_SNR in range (1):\n",
    "        correct = 0\n",
    "        correct2 = 0\n",
    "        correct3 = 0\n",
    "        scores, labels = [], []\n",
    "\n",
    "        inputs=torch.from_numpy(X_test1).float().cuda()\n",
    "        #targets=torch.from_numpy(ytest1[num_s*800+num_SNR*100+0:num_s*800+num_SNR*100+100]).float().cuda()\n",
    "        #targets=targets.long()\n",
    "        _,outputs = net(inputs)\n",
    "        scores.append(outputs)\n",
    "        labels.append(targets)\n",
    "        \n",
    "        scores = torch.cat(scores,dim=0).cpu().detach().numpy()\n",
    "        labels = torch.cat(labels,dim=0).cpu().detach().numpy()     \n",
    "        \n",
    "        \n",
    "        \n",
    "        scores = np.array(scores)[:, np.newaxis, :]\n",
    "        labels = np.array(labels) \n",
    "\n",
    "        pred_Recalibrate = []\n",
    "        score_Recalibrate = []\n",
    "        \n",
    "        for score in scores:\n",
    "            so, ss = Recalibrate(weibull_model, categories, score,\n",
    "                             0.5, 3, \"euclidean\")\n",
    "            pred_Recalibrate.append(np.argmax(so))\n",
    "            score_Recalibrate.append(so)        \n",
    "        pred_Recalibrate = torch.from_numpy(np.array(pred_Recalibrate))\n",
    "        \n",
    "\n",
    "acc=0\n",
    "for ii in range(100):\n",
    "    if pred_Recalibrate[ii]==14:\n",
    "        acc=acc+1\n",
    "print(acc)   "
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.7.11"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
